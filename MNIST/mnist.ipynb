{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "Welcome to your fifth homework assignment for CSC 294. In this \n",
    "assignment, we will practice implementing cross-validation. \n",
    "\n",
    "In this assignment, we will use a dataset similar to our (fake) \n",
    "employee dataset, encoded in the `hw5data.csv` file. In this data \n",
    "set, there are four variables: a new hire's score on the big five \n",
    "personality test (`neuroticism`), their most recent performance score \n",
    "(`performance`), their job type (`job`), and their current salary. \n",
    "Our goal is to determine what relationship -- if any -- salary has \n",
    "with the other three variables. \n",
    "\n",
    "A few notes before we begin:\n",
    "1. For this assignment, please submit your work in the jupyter \n",
    "   notebook called `hw5_notebook.ipynb`. \n",
    "2. There are unit tests for this assignment, so that you can check \n",
    "   that elements of your code work. Place these elements in the file \n",
    "   called `hw5.py`. Note that part of the assignment is showing that \n",
    "   the tests pass locally and on github actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>performance</th>\n",
       "      <th>job</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.199914</td>\n",
       "      <td>51.564036</td>\n",
       "      <td>technical</td>\n",
       "      <td>106243.048181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.030238</td>\n",
       "      <td>49.450498</td>\n",
       "      <td>manager</td>\n",
       "      <td>112692.776165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.269581</td>\n",
       "      <td>52.500872</td>\n",
       "      <td>technical</td>\n",
       "      <td>103622.369119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.025011</td>\n",
       "      <td>42.019628</td>\n",
       "      <td>technical</td>\n",
       "      <td>109914.369855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.661687</td>\n",
       "      <td>70.396598</td>\n",
       "      <td>manager</td>\n",
       "      <td>126709.849574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3.998330</td>\n",
       "      <td>50.646126</td>\n",
       "      <td>technical</td>\n",
       "      <td>107888.959496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4.644208</td>\n",
       "      <td>66.356879</td>\n",
       "      <td>technical</td>\n",
       "      <td>116504.876854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4.455327</td>\n",
       "      <td>42.240215</td>\n",
       "      <td>manager</td>\n",
       "      <td>114126.650852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3.004574</td>\n",
       "      <td>38.122114</td>\n",
       "      <td>manager</td>\n",
       "      <td>110904.164358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3.393171</td>\n",
       "      <td>34.341145</td>\n",
       "      <td>manager</td>\n",
       "      <td>108925.290762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     neuroticism  performance        job         salary\n",
       "0       3.199914    51.564036  technical  106243.048181\n",
       "1       2.030238    49.450498    manager  112692.776165\n",
       "2       4.269581    52.500872  technical  103622.369119\n",
       "3       3.025011    42.019628  technical  109914.369855\n",
       "4       2.661687    70.396598    manager  126709.849574\n",
       "..           ...          ...        ...            ...\n",
       "995     3.998330    50.646126  technical  107888.959496\n",
       "996     4.644208    66.356879  technical  116504.876854\n",
       "997     4.455327    42.240215    manager  114126.650852\n",
       "998     3.004574    38.122114    manager  110904.164358\n",
       "999     3.393171    34.341145    manager  108925.290762\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Import Block\n",
    "data = pd.read_csv(\"hw5data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of columns from that dataset that need to be pre-processed into numerical values\n",
    "colsToMakeIntType = []\n",
    "for col in data:\n",
    "    if data.dtypes[col] == 'object':\n",
    "        colsToMakeIntType.append(col)\n",
    "colsToMakeIntType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job'], dtype='<U3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#practice\n",
    "unique_values = np.unique(colsToMakeIntType)\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: data_wrangle function\n",
    "def data_wrangle(filename, colsToMakeIntType):\n",
    "    \n",
    "    #For each column listed as an input (ie. those with non-numerical data): \n",
    "    for col in colsToMakeIntType:\n",
    "        #Determine the unique values in that column\n",
    "        unique_values = np.unique(col)\n",
    "        #Convert the unique values to numbers\n",
    "        for item in col:\n",
    "            unique_values[i] = i\n",
    "            data[col][item] = i\n",
    "        return colsToMakeIntType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_wrangle() missing 2 required positional arguments: 'filename' and 'colsToMakeIntType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_wrangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: data_wrangle() missing 2 required positional arguments: 'filename' and 'colsToMakeIntType'"
     ]
    }
   ],
   "source": [
    "data_wrangle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra function\n",
    "\n",
    "def compute_mse(truth_vec, predict_vec):\n",
    "    return np.mean((truth_vec - predict_vec)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Pre-processing the data\n",
    "\n",
    "Given that our implementations for linear regression assume that our \n",
    "data is in the form of a numpy array, we need to ensure that we can \n",
    "import our data as such. \n",
    "\n",
    "This means that we need to check that each column of our data \n",
    "contains numbers. If it does not, then we need to convert the \n",
    "information in those columns to numbers. For example, suppose that \n",
    "we have a variable of favorite colors with possible values `red`, \n",
    "`blue`, and `green`. We might convert this information such that \n",
    "`red` becomes 0, `blue` becomes 1, and `green` becomes 2. \n",
    "\n",
    "For this problem, create a function `data_wrangle` (in `hw5.py`) that \n",
    "will take an input `filename` and a list of columns from that dataset \n",
    "that need to be pre-processed into numerical values. Your function \n",
    "should:    \n",
    "1. Import the data with `pandas` \n",
    "2. For each column listed as an input (ie. those with non-numerical \n",
    "   data):\n",
    "   * Determine the unique values in that column\n",
    "   * Convert the unique values in into unique numbers. \n",
    "3. Then the function should extract the data's column names from \n",
    "   the observation rows.  \n",
    "4. The data should then be converted to a numpy array\n",
    "5. Finally `data_wrangle` should output all of the column names in \n",
    "   order as well as the converted dataset. \n",
    "\n",
    "_Hint:_ If your tests are throwing odd errors, you may need to \n",
    "convert the `type` of your final numpy array using `.astype(float)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrangle(dataset_file, lst):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Implement k-fold Cross-Validation\n",
    "\n",
    "Create a function `kfold_CV` (in `hw5.py`) that implements k-fold \n",
    "cross-validation. \n",
    "The inputs, in order, should be:\n",
    "1. The full dataset (as a numpy array)\n",
    "2. The header list (as in the list of variable/column names, in the \n",
    "   the order that they appear in the dataset)\n",
    "3. Input variables\n",
    "4. Output variables\n",
    "5. Value for _k_\n",
    "\n",
    "Using these inputs, `kfold_CV` should extract the input and output \n",
    "variables from the full dataset, divide the data into the _k_ folds, \n",
    "determine the linear relationship for the output variable given the \n",
    "input variables for each fold, and then `kfold_CV` should output only \n",
    "the cross-validated error as a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV(data, col_names, inputs, output, k):\n",
    "    #extract the input and output variables from the full dataset\n",
    "    inputs = data[inputs]\n",
    "    output = data[output]\n",
    "\n",
    "\n",
    "    #divide the data into the k folds. split_dataframes is a list now\n",
    "    split_dataframe = []\n",
    "    index_to_split = len(data) // k\n",
    "    start = 0\n",
    "    end = index_to_split\n",
    "    for split in range(k):\n",
    "        temporary_df = data.iloc[start:end, :]\n",
    "        split_dataframes.append(temporary_df)\n",
    "        start += index_to_split\n",
    "        end += index_to_split\n",
    "\n",
    "    #determine the linear relationship for the output variable given the input variables for each fold\n",
    "    #fit but dont predict\n",
    "    lin_relationships = []\n",
    "    for fold in split_dataframes:\n",
    "        lin_relationships.append(fold)\n",
    "\n",
    "    #output only the cross-validated error as a float #from lab 13\n",
    "    # Find the number of data points in your data\n",
    "    #n_data = data.shape[0]\n",
    "    n_data = data[0]\n",
    "\n",
    "    # Initialize the list of errors\n",
    "    test_errors = []\n",
    "\n",
    "    # Loop over all points in the data set, letting each act as the test set\n",
    "    for i in range(n_data):\n",
    "\n",
    "        # Split data into train and test\n",
    "        test_data = n_data[i]\n",
    "        train_data = n_data[:i] + n_data[i+1:]\n",
    "\n",
    "        # Create and train a model\n",
    "        lm= linear_model.LinearRegression()\n",
    "        mod = lm.fit(train_data[:,1:3], train_data[:,0]) # work here\n",
    "\n",
    "        # Compute the testing error and add it to the list of testing errors\n",
    "        #preds = mod.predict(test_data[:,1:3])\n",
    "        t_error = compute_mse(test_data[:,0],mod)\n",
    "        test_errors.append(t_error)\n",
    "\n",
    "    # Compute the cross-val error\n",
    "    return np.mean(test_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     neuroticism  performance        job         salary\n",
      "0       3.199914    51.564036  technical  106243.048181\n",
      "1       2.030238    49.450498    manager  112692.776165\n",
      "2       4.269581    52.500872  technical  103622.369119\n",
      "3       3.025011    42.019628  technical  109914.369855\n",
      "4       2.661687    70.396598    manager  126709.849574\n",
      "..           ...          ...        ...            ...\n",
      "495     3.116976    43.975946    manager  110385.952782\n",
      "496     4.020593    74.082378  technical  116337.598175\n",
      "497     1.999254    37.803076  technical  110911.510930\n",
      "498     2.439240    47.376813  technical  113814.697618\n",
      "499     2.827729    54.672298  technical  116818.500367\n",
      "\n",
      "[500 rows x 4 columns],      neuroticism  performance        job         salary\n",
      "500     2.493154    39.287936  technical  103820.307764\n",
      "501     2.573965    21.175394  technical   98863.576229\n",
      "502     2.309524    47.197614  technical  114497.325655\n",
      "503     3.557913    63.716685  technical  108760.648049\n",
      "504     3.958743    39.964175    manager  106164.629911\n",
      "..           ...          ...        ...            ...\n",
      "995     3.998330    50.646126  technical  107888.959496\n",
      "996     4.644208    66.356879  technical  116504.876854\n",
      "997     4.455327    42.240215    manager  114126.650852\n",
      "998     3.004574    38.122114    manager  110904.164358\n",
      "999     3.393171    34.341145    manager  108925.290762\n",
      "\n",
      "[500 rows x 4 columns]]\n"
     ]
    }
   ],
   "source": [
    "#https://datagy.io/split-pandas-dataframe/\n",
    "def split_dataframe_by_position(data, k):\n",
    "    dataframes = []\n",
    "    index_to_split = len(data) // k\n",
    "    start = 0\n",
    "    end = index_to_split\n",
    "    for split in range(k):\n",
    "        temporary_df = data.iloc[start:end, :]\n",
    "        dataframes.append(temporary_df)\n",
    "        start += index_to_split\n",
    "        end += index_to_split\n",
    "    return dataframes\n",
    "split_dataframes = split_dataframe_by_position(data, 2)\n",
    "print(split_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Use 10-fold Cross-Validation\n",
    "\n",
    "Using your function from question 2, import `hw5.py` into your \n",
    "jupyter notebook. Now use `kfold_CV` to determine the shape of the \n",
    "\"true\" relationship for `salary`. \n",
    "\n",
    "Test the following combinations of input variables:\n",
    "* `neuroticism`\n",
    "* `performance`\n",
    "* `job`\n",
    "* `neuroticism` and `performance`\n",
    "* `neuroticism` and `job`\n",
    "* `performance` and `job`\n",
    "* `neuroticism`, `performance` and `job`\n",
    "\n",
    "Using 10-fold cross-val, choose which combination yields the best \n",
    "relationship for describing `salary` and justify your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Determine the full model\n",
    "\n",
    "Once you have determined what variables your model should include, \n",
    "find the actual coeffients for the model using all of the dataset. \n",
    "Explain why using all of the data in the creation of the model is \n",
    "appropriate in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
